{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e0ceaed",
   "metadata": {},
   "source": [
    "All transformations learned by deep neural networks can be reduced to a handful of tensor operations (or tensor functions) applied to tensors of numeric data. It's possible to add tensors, multiply tensors, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcf464e",
   "metadata": {},
   "source": [
    "### Element-wise operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f73f4b",
   "metadata": {},
   "source": [
    "- The relu operation and addition are element-wise operations that are applied independently to each entry in the tensors being considered.\n",
    "- This means these operations are highly amenable to massively parallel implementations (vectorized implementations).\n",
    "- If you want to write a naive Python implementation of an element-wise operation, you use a for loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da2b572",
   "metadata": {},
   "source": [
    "ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f39d0c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_relu(x):\n",
    "    assert len(x.shape) == 2\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] = max(x[i, j], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c01d692",
   "metadata": {},
   "source": [
    "Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4edc18d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_add(x,y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert x.shape == y.shape\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i, j] += y[i, j]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2546b9f2",
   "metadata": {},
   "source": [
    "n practice, when dealing with NumPy arrays, these operations are available as well-optimized built-in NumPy functions, which themselves delegate the heavy lifting  to a Basic Linear Algebra Subprograms (BLAS) implementation (low-level, highly parallel, efficient tensor-manipulation routines that are typically implemented in Fortran or C).m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456bd334",
   "metadata": {},
   "source": [
    "So in NumPy, you can do the following element-wise operation, and it will be blazing fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07ed66bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 0.008999 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "x = np.random.random((20,100))\n",
    "y = np.random.random((20,100))\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "for _ in range(1000):\n",
    "    z = x + y\n",
    "    z = np.maximum(z, 0)\n",
    "    \n",
    "print(\"Took: {0:2f} s\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81219d5",
   "metadata": {},
   "source": [
    "Meanwhile the naive version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a8e8408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took: 4.779998 s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "for _ in range(1000):\n",
    "    z = naive_add(x, y)\n",
    "    z = naive_relu(z)\n",
    "    \n",
    "print(\"Took: {0:2f} s\".format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68780d2c",
   "metadata": {},
   "source": [
    "Likewise, when running TensorFlow code on a GPU, element-wise operations are executed via fully vectorized CUDA implementations that can best utilize the highly parallel GPU chip architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab09323",
   "metadata": {},
   "source": [
    "#### Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995c11ed",
   "metadata": {},
   "source": [
    "- What happens with addition when the shapes of the two tensors being added differ?\n",
    "- When possible, when there's no ambiguity, the smaller tensor will be broadcast to match the shape of the larger tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8546aebc",
   "metadata": {},
   "source": [
    "- Broadcasting consists of two steps:\n",
    "\t- Axes (called broadcast axis) are added to the smaller tensor to match the ndim of the larger tensor.\n",
    "\t- The smaller tensor is repeated alongside these new axes to match the full shape of the larger tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce740d5a",
   "metadata": {},
   "source": [
    "Let's look at a concrete example. Consider X with shape (32,10) and y with shape (10,):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b954e7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.random.random((32,10))\n",
    "y = np.random.random((10,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3263081e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.52040019, 0.11364975, 0.79379005, 0.2826918 , 0.81832712,\n",
       "        0.30051143, 0.69614454, 0.95671423, 0.19789542, 0.80455648],\n",
       "       [0.59027225, 0.26480535, 0.71874721, 0.38362018, 0.87490661,\n",
       "        0.24829111, 0.92076838, 0.40430915, 0.77322922, 0.55622764],\n",
       "       [0.8216292 , 0.65650194, 0.13979498, 0.04938335, 0.92196324,\n",
       "        0.75124839, 0.16512904, 0.98321442, 0.89604952, 0.88466392],\n",
       "       [0.56739504, 0.21704017, 0.19072295, 0.37317848, 0.48155987,\n",
       "        0.68713767, 0.13410949, 0.49334919, 0.98036186, 0.35933354],\n",
       "       [0.70157012, 0.4401658 , 0.90793161, 0.69475223, 0.1767852 ,\n",
       "        0.15887621, 0.89699658, 0.27212976, 0.28393734, 0.23981372],\n",
       "       [0.66217616, 0.76878214, 0.94084423, 0.46567931, 0.86021226,\n",
       "        0.06449526, 0.72396059, 0.00609476, 0.9005034 , 0.2455131 ],\n",
       "       [0.35030332, 0.7098137 , 0.93271561, 0.39008344, 0.68197308,\n",
       "        0.27242743, 0.37274262, 0.80335723, 0.47622014, 0.03283213],\n",
       "       [0.94184011, 0.64927805, 0.05353247, 0.52600307, 0.08073156,\n",
       "        0.7653937 , 0.13603528, 0.69224515, 0.9801577 , 0.73801418],\n",
       "       [0.23511953, 0.63755865, 0.98374892, 0.45031193, 0.66833825,\n",
       "        0.20112904, 0.68190015, 0.89357255, 0.91022401, 0.21307979],\n",
       "       [0.83341979, 0.02316894, 0.21538286, 0.44289013, 0.0911985 ,\n",
       "        0.93512534, 0.11833604, 0.4855949 , 0.12427102, 0.71781797],\n",
       "       [0.14459669, 0.1387676 , 0.36781602, 0.80308928, 0.88867264,\n",
       "        0.17889765, 0.93831839, 0.02993983, 0.60337042, 0.02857753],\n",
       "       [0.67771679, 0.28246223, 0.53678161, 0.70161662, 0.42328539,\n",
       "        0.69340498, 0.83380532, 0.85046586, 0.33468026, 0.83895395],\n",
       "       [0.05798488, 0.45094819, 0.5933157 , 0.4309313 , 0.5036967 ,\n",
       "        0.79679449, 0.28480795, 0.26517939, 0.66250961, 0.95644471],\n",
       "       [0.52796101, 0.90414515, 0.83046706, 0.90301052, 0.69805293,\n",
       "        0.88465141, 0.9331635 , 0.77233601, 0.72684042, 0.20131495],\n",
       "       [0.58469288, 0.81839977, 0.58510414, 0.33818227, 0.15435473,\n",
       "        0.42888026, 0.07311753, 0.88309011, 0.22325093, 0.43081946],\n",
       "       [0.63932136, 0.3315474 , 0.19802273, 0.14070861, 0.53378154,\n",
       "        0.37363307, 0.93936272, 0.84224251, 0.59911413, 0.39085016],\n",
       "       [0.31168773, 0.69827189, 0.10368664, 0.43673152, 0.17630101,\n",
       "        0.70796298, 0.42658638, 0.84846538, 0.08379756, 0.95623652],\n",
       "       [0.10036313, 0.744358  , 0.7015805 , 0.58303616, 0.18434602,\n",
       "        0.25418174, 0.95023883, 0.01513105, 0.15170748, 0.82199745],\n",
       "       [0.09859158, 0.01427401, 0.74968886, 0.21422677, 0.48555023,\n",
       "        0.36850127, 0.39679494, 0.11249692, 0.1735257 , 0.02004313],\n",
       "       [0.68960172, 0.97289204, 0.68950832, 0.7555189 , 0.27776706,\n",
       "        0.46069823, 0.74218867, 0.37485955, 0.88780425, 0.74843307],\n",
       "       [0.74567053, 0.73028671, 0.97212219, 0.56036582, 0.1325993 ,\n",
       "        0.48460303, 0.41209616, 0.92896049, 0.32716814, 0.8439058 ],\n",
       "       [0.01452001, 0.03141827, 0.60862675, 0.46024841, 0.85817997,\n",
       "        0.15001071, 0.06968322, 0.66845822, 0.09503259, 0.61601422],\n",
       "       [0.80986602, 0.69664327, 0.68016365, 0.49648171, 0.9079386 ,\n",
       "        0.41953306, 0.48449755, 0.76242177, 0.35389201, 0.84809915],\n",
       "       [0.39444178, 0.07891001, 0.86272306, 0.84048974, 0.14866113,\n",
       "        0.09257664, 0.04340631, 0.03946611, 0.90415614, 0.31199262],\n",
       "       [0.30111921, 0.48715751, 0.22693441, 0.00204331, 0.3621532 ,\n",
       "        0.56391193, 0.72332313, 0.91807997, 0.78083248, 0.61957546],\n",
       "       [0.01266785, 0.56665095, 0.57670095, 0.4767606 , 0.51308899,\n",
       "        0.88254295, 0.38225163, 0.75773593, 0.19035241, 0.38169481],\n",
       "       [0.71007925, 0.82308582, 0.54629051, 0.67048079, 0.50842461,\n",
       "        0.70223939, 0.67455227, 0.62246735, 0.02539909, 0.38725502],\n",
       "       [0.72757556, 0.83212924, 0.57825413, 0.49600844, 0.55363016,\n",
       "        0.74342421, 0.81138831, 0.4432815 , 0.92881142, 0.40122324],\n",
       "       [0.85074047, 0.16161228, 0.18943042, 0.2449349 , 0.69186733,\n",
       "        0.43088099, 0.65517895, 0.64515399, 0.36982401, 0.27040017],\n",
       "       [0.85307707, 0.42504293, 0.94885393, 0.16678742, 0.69626423,\n",
       "        0.93436028, 0.96775379, 0.33801477, 0.05439838, 0.82451425],\n",
       "       [0.01185023, 0.85048313, 0.59196901, 0.31485648, 0.03609086,\n",
       "        0.48373739, 0.29824643, 0.23984396, 0.11076697, 0.52603187],\n",
       "       [0.69330051, 0.31605135, 0.14433483, 0.80157823, 0.25546429,\n",
       "        0.20837039, 0.40493512, 0.0074156 , 0.72131638, 0.99410776]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68fd91d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65730044, 0.71045142, 0.53709828, 0.44315067, 0.66300613,\n",
       "       0.82663649, 0.88057878, 0.9424155 , 0.84131204, 0.8494456 ])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc13f7c",
   "metadata": {},
   "source": [
    "First, we add an empty first axis to y, whose shape becomes (1,10):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50f52942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.65730044, 0.71045142, 0.53709828, 0.44315067, 0.66300613,\n",
       "        0.82663649, 0.88057878, 0.9424155 , 0.84131204, 0.8494456 ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.expand_dims(y, axis=0)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79174c79",
   "metadata": {},
   "source": [
    "Then, we repeat y 32 times alongside this new axis, so that we end up with a tensor Y with shape (32,10), where Y([i, :] == y for i in range (0,32):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dfdfcbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.concatenate([y] * 32, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c05cafda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.65730044, 0.71045142, 0.53709828, 0.44315067, 0.66300613,\n",
       "        0.82663649, 0.88057878, 0.9424155 , 0.84131204, 0.8494456 ],\n",
       "       [0.65730044, 0.71045142, 0.53709828, 0.44315067, 0.66300613,\n",
       "        0.82663649, 0.88057878, 0.9424155 , 0.84131204, 0.8494456 ],\n",
       "       [0.65730044, 0.71045142, 0.53709828, 0.44315067, 0.66300613,\n",
       "        0.82663649, 0.88057878, 0.9424155 , 0.84131204, 0.8494456 ],\n",
       "       [0.65730044, 0.71045142, 0.53709828, 0.44315067, 0.66300613,\n",
       "        0.82663649, 0.88057878, 0.9424155 , 0.84131204, 0.8494456 ],\n",
       "       [0.65730044, 0.71045142, 0.53709828, 0.44315067, 0.66300613,\n",
       "        0.82663649, 0.88057878, 0.9424155 , 0.84131204, 0.8494456 ],\n",
       "       [0.65730044, 0.71045142, 0.53709828, 0.44315067, 0.66300613,\n",
       "        0.82663649, 0.88057878, 0.9424155 , 0.84131204, 0.8494456 ],\n",
       "       [0.65730044, 0.71045142, 0.53709828, 0.44315067, 0.66300613,\n",
       "        0.82663649, 0.88057878, 0.9424155 , 0.84131204, 0.8494456 ],\n",
       "       [0.65730044, 0.71045142, 0.53709828, 0.44315067, 0.66300613,\n",
       "        0.82663649, 0.88057878, 0.9424155 , 0.84131204, 0.8494456 ],\n",
       "       [0.65730044, 0.71045142, 0.53709828, 0.44315067, 0.66300613,\n",
       "        0.82663649, 0.88057878, 0.9424155 , 0.84131204, 0.8494456 ],\n",
       "       [0.65730044, 0.71045142, 0.53709828, 0.44315067, 0.66300613,\n",
       "        0.82663649, 0.88057878, 0.9424155 , 0.84131204, 0.8494456 ],\n",
       "       [0.65730044, 0.71045142, 0.53709828, 0.44315067, 0.66300613,\n",
       "        0.82663649, 0.88057878, 0.9424155 , 0.84131204, 0.8494456 ],\n",
       "       [0.65730044, 0.71045142, 0.53709828, 0.44315067, 0.66300613,\n",
       "        0.82663649, 0.88057878, 0.9424155 , 0.84131204, 0.8494456 ],\n",
       "       [0.65730044, 0.71045142, 0.53709828, 0.44315067, 0.66300613,\n",
       "        0.82663649, 0.88057878, 0.9424155 , 0.84131204, 0.8494456 ],\n",
       "       [0.65730044, 0.71045142, 0.53709828, 0.44315067, 0.66300613,\n",
       "        0.82663649, 0.88057878, 0.9424155 , 0.84131204, 0.8494456 ],\n",
       "       [0.65730044, 0.71045142, 0.53709828, 0.44315067, 0.66300613,\n",
       "        0.82663649, 0.88057878, 0.9424155 , 0.84131204, 0.8494456 ],\n",
       "       [0.65730044, 0.71045142, 0.53709828, 0.44315067, 0.66300613,\n",
       "        0.82663649, 0.88057878, 0.9424155 , 0.84131204, 0.8494456 ],\n",
       "       [0.65730044, 0.71045142, 0.53709828, 0.44315067, 0.66300613,\n",
       "        0.82663649, 0.88057878, 0.9424155 , 0.84131204, 0.8494456 ],\n",
       "       [0.65730044, 0.71045142, 0.53709828, 0.44315067, 0.66300613,\n",
       "        0.82663649, 0.88057878, 0.9424155 , 0.84131204, 0.8494456 ],\n",
       "       [0.65730044, 0.71045142, 0.53709828, 0.44315067, 0.66300613,\n",
       "        0.82663649, 0.88057878, 0.9424155 , 0.84131204, 0.8494456 ],\n",
       "       [0.65730044, 0.71045142, 0.53709828, 0.44315067, 0.66300613,\n",
       "        0.82663649, 0.88057878, 0.9424155 , 0.84131204, 0.8494456 ],\n",
       "       [0.65730044, 0.71045142, 0.53709828, 0.44315067, 0.66300613,\n",
       "        0.82663649, 0.88057878, 0.9424155 , 0.84131204, 0.8494456 ],\n",
       "       [0.65730044, 0.71045142, 0.53709828, 0.44315067, 0.66300613,\n",
       "        0.82663649, 0.88057878, 0.9424155 , 0.84131204, 0.8494456 ],\n",
       "       [0.65730044, 0.71045142, 0.53709828, 0.44315067, 0.66300613,\n",
       "        0.82663649, 0.88057878, 0.9424155 , 0.84131204, 0.8494456 ],\n",
       "       [0.65730044, 0.71045142, 0.53709828, 0.44315067, 0.66300613,\n",
       "        0.82663649, 0.88057878, 0.9424155 , 0.84131204, 0.8494456 ],\n",
       "       [0.65730044, 0.71045142, 0.53709828, 0.44315067, 0.66300613,\n",
       "        0.82663649, 0.88057878, 0.9424155 , 0.84131204, 0.8494456 ],\n",
       "       [0.65730044, 0.71045142, 0.53709828, 0.44315067, 0.66300613,\n",
       "        0.82663649, 0.88057878, 0.9424155 , 0.84131204, 0.8494456 ],\n",
       "       [0.65730044, 0.71045142, 0.53709828, 0.44315067, 0.66300613,\n",
       "        0.82663649, 0.88057878, 0.9424155 , 0.84131204, 0.8494456 ],\n",
       "       [0.65730044, 0.71045142, 0.53709828, 0.44315067, 0.66300613,\n",
       "        0.82663649, 0.88057878, 0.9424155 , 0.84131204, 0.8494456 ],\n",
       "       [0.65730044, 0.71045142, 0.53709828, 0.44315067, 0.66300613,\n",
       "        0.82663649, 0.88057878, 0.9424155 , 0.84131204, 0.8494456 ],\n",
       "       [0.65730044, 0.71045142, 0.53709828, 0.44315067, 0.66300613,\n",
       "        0.82663649, 0.88057878, 0.9424155 , 0.84131204, 0.8494456 ],\n",
       "       [0.65730044, 0.71045142, 0.53709828, 0.44315067, 0.66300613,\n",
       "        0.82663649, 0.88057878, 0.9424155 , 0.84131204, 0.8494456 ],\n",
       "       [0.65730044, 0.71045142, 0.53709828, 0.44315067, 0.66300613,\n",
       "        0.82663649, 0.88057878, 0.9424155 , 0.84131204, 0.8494456 ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c418d64",
   "metadata": {},
   "source": [
    "- At this point, we can proceed to add X and Y, because they have the same shape.\n",
    "- In terms of implementation, no new rank-2 tensor is created, because that would be terribly inefficient.\n",
    "- The repetition operation is entirely virtual: it happens at the algorithmic level rather than at the memory level. But thinking of the vector being repeated 10 times alongside a new axis is a helpful mental model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d89d75b",
   "metadata": {},
   "source": [
    "Here's what a naive implementation would look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0f75906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_add_matrix_and_vector(x,y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert len(y.shape) == 2\n",
    "    assert x.shape[1] == y.shape[0]\n",
    "    x = x.copy()\n",
    "    for i in range(x.shape[0]):\n",
    "        for k in range(x.shape[1]):\n",
    "            x[i, j] += y[j]\n",
    "    return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
